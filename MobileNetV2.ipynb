{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense,GlobalAveragePooling2D\n",
    "from keras.applications import MobileNetV2\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/spxylla/anaconda3/envs/dd2424/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spxylla/anaconda3/envs/dd2424/lib/python3.7/site-packages/keras_applications/mobilenet_v2.py:295: UserWarning: MobileNet shape is undefined. Weights for input shape(224, 224) will be loaded.\n",
      "  warnings.warn('MobileNet shape is undefined.'\n"
     ]
    }
   ],
   "source": [
    "model_name='MobileNetV2'\n",
    "number_of_epochs = 100\n",
    "frozen = False\n",
    "\n",
    "base_model=MobileNetV2(weights='imagenet',include_top=False) #imports the mobilenet model and discards the last 1000 neuron layer.\n",
    "\n",
    "if frozen:\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    \n",
    "x = base_model.output\n",
    "\n",
    "#These layers act as output layer for mobilenet but are customed to fit for 6 classes instead of imagenets original 1000.\n",
    "x=GlobalAveragePooling2D()(x)\n",
    "x=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
    "x=Dense(1024,activation='relu')(x) #dense layer 2\n",
    "x=Dense(512,activation='relu')(x) #dense layer 3\n",
    "preds=Dense(6,activation='softmax')(x) #final layer with softmax activation\n",
    "\n",
    "\n",
    "#%%\n",
    "\n",
    "model=Model(inputs=base_model.input,outputs=preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1825 images belonging to 6 classes.\n",
      "Found 271 images belonging to 6 classes.\n",
      "Found 431 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = dict(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "\t\tvalidation_split=0.13,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input, **datagen)\n",
    "\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory('./dataset/train',\n",
    "                                                 target_size=(224,224),\n",
    "                                                 color_mode='rgb',\n",
    "                                                 batch_size=32,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 subset='training')\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory('./dataset/train',\n",
    "                                                 target_size=(224,224),\n",
    "                                                 color_mode='rgb',\n",
    "                                                 batch_size=train_generator.batch_size,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 subset='validation')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory('./dataset/test',\n",
    "                                                 target_size=(224,224),\n",
    "                                                 color_mode='rgb',\n",
    "                                                 batch_size=1,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 shuffle=False\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/spxylla/anaconda3/envs/dd2424/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "57/57 [==============================] - 36s 632ms/step - loss: 1.1889 - acc: 0.5702 - val_loss: 1.6170 - val_acc: 0.4336\n",
      "Epoch 2/100\n",
      "57/57 [==============================] - 27s 476ms/step - loss: 0.9363 - acc: 0.6636 - val_loss: 1.6290 - val_acc: 0.5523\n",
      "Epoch 3/100\n",
      "57/57 [==============================] - 28s 486ms/step - loss: 0.8502 - acc: 0.7118 - val_loss: 4.0138 - val_acc: 0.3598\n",
      "Epoch 4/100\n",
      "57/57 [==============================] - 28s 492ms/step - loss: 0.6972 - acc: 0.7768 - val_loss: 3.5784 - val_acc: 0.3515\n",
      "Epoch 5/100\n",
      "57/57 [==============================] - 28s 490ms/step - loss: 0.8329 - acc: 0.7223 - val_loss: 4.2812 - val_acc: 0.2092\n",
      "Epoch 6/100\n",
      "57/57 [==============================] - 28s 494ms/step - loss: 0.6915 - acc: 0.7656 - val_loss: 5.4236 - val_acc: 0.2469\n",
      "Epoch 7/100\n",
      "57/57 [==============================] - 28s 488ms/step - loss: 0.6551 - acc: 0.7919 - val_loss: 2.6186 - val_acc: 0.5146\n",
      "Epoch 8/100\n",
      "57/57 [==============================] - 28s 494ms/step - loss: 0.5665 - acc: 0.8210 - val_loss: 6.9323 - val_acc: 0.2218\n",
      "Epoch 9/100\n",
      "57/57 [==============================] - 28s 488ms/step - loss: 0.5500 - acc: 0.8199 - val_loss: 2.6920 - val_acc: 0.3556\n",
      "Epoch 10/100\n",
      "57/57 [==============================] - 28s 490ms/step - loss: 0.5291 - acc: 0.8451 - val_loss: 4.5339 - val_acc: 0.3477\n",
      "Epoch 11/100\n",
      "57/57 [==============================] - 28s 489ms/step - loss: 0.5223 - acc: 0.8341 - val_loss: 5.4716 - val_acc: 0.2887\n",
      "Epoch 12/100\n",
      "57/57 [==============================] - 28s 489ms/step - loss: 0.4697 - acc: 0.8522 - val_loss: 3.9417 - val_acc: 0.3849\n",
      "Epoch 13/100\n",
      "57/57 [==============================] - 28s 488ms/step - loss: 0.5029 - acc: 0.8363 - val_loss: 7.2513 - val_acc: 0.3096\n",
      "Epoch 14/100\n",
      "57/57 [==============================] - 28s 493ms/step - loss: 0.3873 - acc: 0.8676 - val_loss: 2.2175 - val_acc: 0.5063\n",
      "Epoch 15/100\n",
      "57/57 [==============================] - 28s 489ms/step - loss: 0.4192 - acc: 0.8815 - val_loss: 2.2829 - val_acc: 0.4895\n",
      "Epoch 16/100\n",
      "57/57 [==============================] - 28s 486ms/step - loss: 0.3809 - acc: 0.8659 - val_loss: 4.3578 - val_acc: 0.4017\n",
      "Epoch 17/100\n",
      "57/57 [==============================] - 28s 493ms/step - loss: 0.3901 - acc: 0.8714 - val_loss: 3.3874 - val_acc: 0.4017\n",
      "Epoch 18/100\n",
      "57/57 [==============================] - 28s 489ms/step - loss: 0.3650 - acc: 0.8786 - val_loss: 2.4814 - val_acc: 0.5816\n",
      "Epoch 19/100\n",
      "57/57 [==============================] - 28s 491ms/step - loss: 0.3511 - acc: 0.8881 - val_loss: 2.7206 - val_acc: 0.5078\n",
      "Epoch 20/100\n",
      "57/57 [==============================] - 28s 487ms/step - loss: 0.4261 - acc: 0.8747 - val_loss: 2.6350 - val_acc: 0.4603\n",
      "Epoch 21/100\n",
      "57/57 [==============================] - 28s 497ms/step - loss: 0.3672 - acc: 0.8725 - val_loss: 3.8399 - val_acc: 0.4017\n",
      "Epoch 22/100\n",
      "57/57 [==============================] - 29s 501ms/step - loss: 0.3132 - acc: 0.8961 - val_loss: 2.6645 - val_acc: 0.4477\n",
      "Epoch 23/100\n",
      "57/57 [==============================] - 29s 505ms/step - loss: 0.3659 - acc: 0.8848 - val_loss: 2.9095 - val_acc: 0.4937\n",
      "Epoch 24/100\n",
      "57/57 [==============================] - 28s 495ms/step - loss: 0.3372 - acc: 0.8890 - val_loss: 4.3556 - val_acc: 0.4100\n",
      "Epoch 25/100\n",
      "57/57 [==============================] - 28s 488ms/step - loss: 0.2834 - acc: 0.9016 - val_loss: 4.0895 - val_acc: 0.5105\n",
      "Epoch 26/100\n",
      "57/57 [==============================] - 28s 489ms/step - loss: 0.2222 - acc: 0.9369 - val_loss: 6.3339 - val_acc: 0.3515\n",
      "Epoch 27/100\n",
      "57/57 [==============================] - 28s 495ms/step - loss: 0.3437 - acc: 0.8961 - val_loss: 9.9004 - val_acc: 0.2343\n",
      "Epoch 28/100\n",
      "57/57 [==============================] - 28s 497ms/step - loss: 0.2896 - acc: 0.9021 - val_loss: 5.7083 - val_acc: 0.3633\n",
      "Epoch 29/100\n",
      "57/57 [==============================] - 28s 492ms/step - loss: 0.3279 - acc: 0.9016 - val_loss: 6.1160 - val_acc: 0.2552\n",
      "Epoch 30/100\n",
      "57/57 [==============================] - 28s 489ms/step - loss: 0.2688 - acc: 0.9016 - val_loss: 3.3296 - val_acc: 0.5021\n",
      "Epoch 31/100\n",
      "57/57 [==============================] - 28s 493ms/step - loss: 0.3493 - acc: 0.8983 - val_loss: 4.3114 - val_acc: 0.4519\n",
      "Epoch 32/100\n",
      "57/57 [==============================] - 28s 488ms/step - loss: 0.2462 - acc: 0.9142 - val_loss: 5.9222 - val_acc: 0.4100\n",
      "Epoch 33/100\n",
      "57/57 [==============================] - 28s 494ms/step - loss: 0.2767 - acc: 0.9180 - val_loss: 4.1031 - val_acc: 0.5105\n",
      "Epoch 34/100\n",
      "57/57 [==============================] - 28s 491ms/step - loss: 0.2499 - acc: 0.9186 - val_loss: 2.6952 - val_acc: 0.5230\n",
      "Epoch 35/100\n",
      "57/57 [==============================] - 28s 492ms/step - loss: 0.2987 - acc: 0.9049 - val_loss: 2.5448 - val_acc: 0.5439\n",
      "Epoch 36/100\n",
      "57/57 [==============================] - 28s 494ms/step - loss: 0.2290 - acc: 0.9276 - val_loss: 3.1271 - val_acc: 0.5816\n",
      "Epoch 37/100\n",
      "57/57 [==============================] - 28s 487ms/step - loss: 0.2732 - acc: 0.9120 - val_loss: 2.3648 - val_acc: 0.5703\n",
      "Epoch 38/100\n",
      "57/57 [==============================] - 28s 492ms/step - loss: 0.1861 - acc: 0.9394 - val_loss: 1.8588 - val_acc: 0.6736\n",
      "Epoch 39/100\n",
      "57/57 [==============================] - 28s 499ms/step - loss: 0.2195 - acc: 0.9279 - val_loss: 2.5717 - val_acc: 0.5816\n",
      "Epoch 40/100\n",
      "57/57 [==============================] - 28s 491ms/step - loss: 0.2447 - acc: 0.9158 - val_loss: 1.8046 - val_acc: 0.6402\n",
      "Epoch 41/100\n",
      "57/57 [==============================] - 28s 491ms/step - loss: 0.2506 - acc: 0.9208 - val_loss: 3.7792 - val_acc: 0.2092\n",
      "Epoch 42/100\n",
      "57/57 [==============================] - 28s 485ms/step - loss: 0.2231 - acc: 0.9180 - val_loss: 1.7393 - val_acc: 0.5816\n",
      "Epoch 43/100\n",
      "57/57 [==============================] - 28s 489ms/step - loss: 0.3299 - acc: 0.8994 - val_loss: 2.1974 - val_acc: 0.2594\n",
      "Epoch 44/100\n",
      "57/57 [==============================] - 28s 499ms/step - loss: 0.3610 - acc: 0.8747 - val_loss: 12.2915 - val_acc: 0.1925\n",
      "Epoch 45/100\n",
      "57/57 [==============================] - 28s 492ms/step - loss: 0.2372 - acc: 0.9142 - val_loss: 5.9379 - val_acc: 0.2636\n",
      "Epoch 46/100\n",
      "57/57 [==============================] - 28s 492ms/step - loss: 0.2699 - acc: 0.9131 - val_loss: 9.7168 - val_acc: 0.2500\n",
      "Epoch 47/100\n",
      "57/57 [==============================] - 28s 491ms/step - loss: 0.2375 - acc: 0.9158 - val_loss: 7.9389 - val_acc: 0.2385\n",
      "Epoch 48/100\n",
      "57/57 [==============================] - 28s 487ms/step - loss: 0.2838 - acc: 0.9191 - val_loss: 6.4607 - val_acc: 0.2343\n",
      "Epoch 49/100\n",
      "57/57 [==============================] - 28s 495ms/step - loss: 0.2742 - acc: 0.9032 - val_loss: 5.3128 - val_acc: 0.3264\n",
      "Epoch 50/100\n",
      "57/57 [==============================] - 28s 487ms/step - loss: 0.2879 - acc: 0.9109 - val_loss: 3.6847 - val_acc: 0.2929\n",
      "Epoch 51/100\n",
      "57/57 [==============================] - 28s 492ms/step - loss: 0.2837 - acc: 0.9142 - val_loss: 5.0392 - val_acc: 0.4142\n",
      "Epoch 52/100\n",
      "57/57 [==============================] - 28s 490ms/step - loss: 0.2207 - acc: 0.9268 - val_loss: 5.9311 - val_acc: 0.4393\n",
      "Epoch 53/100\n",
      "57/57 [==============================] - 28s 490ms/step - loss: 0.1825 - acc: 0.9312 - val_loss: 8.3578 - val_acc: 0.3305\n",
      "Epoch 54/100\n",
      "57/57 [==============================] - 28s 490ms/step - loss: 0.2152 - acc: 0.9279 - val_loss: 12.0431 - val_acc: 0.1674\n",
      "Epoch 55/100\n",
      "57/57 [==============================] - 28s 493ms/step - loss: 0.1999 - acc: 0.9263 - val_loss: 11.4932 - val_acc: 0.1758\n",
      "Epoch 56/100\n",
      "57/57 [==============================] - 28s 491ms/step - loss: 0.1692 - acc: 0.9389 - val_loss: 6.5781 - val_acc: 0.3222\n",
      "Epoch 57/100\n",
      "57/57 [==============================] - 28s 487ms/step - loss: 0.2257 - acc: 0.9263 - val_loss: 3.9639 - val_acc: 0.4519\n",
      "Epoch 58/100\n",
      "57/57 [==============================] - 28s 495ms/step - loss: 0.2122 - acc: 0.9372 - val_loss: 5.0490 - val_acc: 0.4854\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 28s 495ms/step - loss: 0.1780 - acc: 0.9452 - val_loss: 2.2021 - val_acc: 0.5774\n",
      "Epoch 60/100\n",
      "57/57 [==============================] - 28s 487ms/step - loss: 0.1385 - acc: 0.9594 - val_loss: 4.6425 - val_acc: 0.3849\n",
      "Epoch 61/100\n",
      "57/57 [==============================] - 28s 491ms/step - loss: 0.3188 - acc: 0.9246 - val_loss: 2.2592 - val_acc: 0.5774\n",
      "Epoch 62/100\n",
      "57/57 [==============================] - 29s 503ms/step - loss: 0.2563 - acc: 0.9115 - val_loss: 3.5277 - val_acc: 0.5272\n",
      "Epoch 63/100\n",
      "57/57 [==============================] - 28s 490ms/step - loss: 0.1690 - acc: 0.9383 - val_loss: 1.9132 - val_acc: 0.6276\n",
      "Epoch 64/100\n",
      "57/57 [==============================] - 28s 490ms/step - loss: 0.1319 - acc: 0.9509 - val_loss: 1.3695 - val_acc: 0.7461\n",
      "Epoch 65/100\n",
      "57/57 [==============================] - 28s 498ms/step - loss: 0.1893 - acc: 0.9416 - val_loss: 3.0714 - val_acc: 0.6025\n",
      "Epoch 66/100\n",
      "57/57 [==============================] - 28s 495ms/step - loss: 0.1361 - acc: 0.9726 - val_loss: 2.8276 - val_acc: 0.5690\n",
      "Epoch 67/100\n",
      "57/57 [==============================] - 28s 489ms/step - loss: 0.1145 - acc: 0.9687 - val_loss: 2.6578 - val_acc: 0.5607\n",
      "Epoch 68/100\n",
      "57/57 [==============================] - 28s 493ms/step - loss: 0.2183 - acc: 0.9383 - val_loss: 3.5658 - val_acc: 0.5565\n",
      "Epoch 69/100\n",
      "57/57 [==============================] - 28s 495ms/step - loss: 0.1221 - acc: 0.9655 - val_loss: 3.9450 - val_acc: 0.5690\n",
      "Epoch 70/100\n",
      "57/57 [==============================] - 28s 495ms/step - loss: 0.1779 - acc: 0.9484 - val_loss: 3.1260 - val_acc: 0.5858\n",
      "Epoch 71/100\n",
      "57/57 [==============================] - 28s 492ms/step - loss: 0.1693 - acc: 0.9466 - val_loss: 4.0013 - val_acc: 0.4728\n",
      "Epoch 72/100\n",
      "57/57 [==============================] - 28s 492ms/step - loss: 0.1656 - acc: 0.9389 - val_loss: 2.8803 - val_acc: 0.5816\n",
      "Epoch 73/100\n",
      "57/57 [==============================] - 28s 497ms/step - loss: 0.1301 - acc: 0.9611 - val_loss: 3.9630 - val_acc: 0.4688\n",
      "Epoch 74/100\n",
      "57/57 [==============================] - 28s 493ms/step - loss: 0.2414 - acc: 0.9334 - val_loss: 4.7074 - val_acc: 0.4770\n",
      "Epoch 75/100\n",
      "57/57 [==============================] - 28s 498ms/step - loss: 0.1667 - acc: 0.9422 - val_loss: 3.4381 - val_acc: 0.5774\n",
      "Epoch 76/100\n",
      "57/57 [==============================] - 35s 610ms/step - loss: 0.1411 - acc: 0.9594 - val_loss: 4.0281 - val_acc: 0.5439\n",
      "Epoch 77/100\n",
      "57/57 [==============================] - 30s 528ms/step - loss: 0.1748 - acc: 0.9482 - val_loss: 2.9258 - val_acc: 0.6025\n",
      "Epoch 78/100\n",
      "57/57 [==============================] - 28s 488ms/step - loss: 0.1508 - acc: 0.9466 - val_loss: 2.0577 - val_acc: 0.6485\n",
      "Epoch 79/100\n",
      "57/57 [==============================] - 28s 492ms/step - loss: 0.1725 - acc: 0.9460 - val_loss: 3.8690 - val_acc: 0.5356\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "#specify the inputs\n",
    "#specify the outputs\n",
    "#now a model has been created based on our architecture\n",
    "\n",
    "\n",
    "#%%\n",
    "\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# Adam optimizer\n",
    "# loss function will be categorical cross entropy\n",
    "# evaluation metric will be accuracy\n",
    "\n",
    "step_size_train = train_generator.n // train_generator.batch_size\n",
    "step_size_validation = validation_generator.n // train_generator.batch_size\n",
    "\n",
    "\n",
    "history = model.fit_generator(generator=train_generator,\n",
    "                   steps_per_epoch=step_size_train,\n",
    "                   validation_data = validation_generator, \n",
    "                   validation_steps = step_size_validation,\n",
    "                   epochs = number_of_epochs)\n",
    "\n",
    "test_loss, test_acc = model.evaluate_generator(generator=test_generator, steps=test_generator.n)\n",
    "\n",
    "#Get history of loss and accuracy during training and display it with graphs\n",
    "train_loss = history.history['loss']\n",
    "train_acc  = history.history['acc']\n",
    "val_loss = history.history['val_loss']\n",
    "val_acc = history.history['val_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "print('train_loss:', train_loss)\n",
    "print('train_acc:', train_acc)\n",
    "print('val_loss:', val_loss)\n",
    "print('val_acc:', val_acc)\n",
    "\"\"\"\n",
    "print('test_loss:', test_loss)\n",
    "print('test_acc:', test_acc) \n",
    "\n",
    "f= open(\"test_results.txt\",\"a+\")\n",
    "f.write(\"____________________________ %s _____________________________ \\r\\n\" % model_name )\n",
    "f.write(\"Number of epochs:%d\\r\\n\" % number_of_epochs)\n",
    "f.write(\"Frozen: %s\\r\\n\" % str(frozen))\n",
    "f.write(\"Test Accuracy:%f\\r\\n\" % test_acc)\n",
    "f.write(\"Test Loss:%f\\r\\n\" % test_loss)\n",
    "f.close()\n",
    "\n",
    "print('A graph displaying the loss over training epochs')\n",
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)\n",
    "plt.title('Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch number')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig('graphs/train_loss_' + model_name + '' + str(number_of_epochs) + 'epochs' + 'Frozen_' + str(frozen) + '.png')\n",
    "\n",
    "\n",
    "\n",
    "print('A graph displaying the accuracy over training epochs')\n",
    "plt.plot(train_acc)\n",
    "plt.plot(val_acc)\n",
    "plt.title('Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch number')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.savefig('graphs/train_acc_' + model_name + '' + str(number_of_epochs) + 'epochs' + 'Frozen_' + str(frozen) + '.png')\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
